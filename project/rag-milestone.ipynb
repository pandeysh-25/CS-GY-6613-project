{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H0kpdhD6cTY8",
    "outputId": "eb1c586b-65f6-49a9-fa54-637a065d14e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.10.1)\n",
      "Requirement already satisfied: qdrant-client in /usr/local/lib/python3.10/dist-packages (1.12.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.7.0)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.68.1)\n",
      "Requirement already satisfied: grpcio-tools>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.68.1)\n",
      "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.26.4)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.10.1)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.10.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.2.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (5.29.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (75.1.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.14.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant-client) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant-client) (2.27.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo qdrant-client nltk sentence-transformers transformers huggingface_hub torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xxMQWJMcTY-"
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GPT2LMHeadModel, GPT2Tokenizer\n",
    "#from huggingface_hub import notebook_login\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PYjzGNUtcTY-",
    "outputId": "dbf6bf12-5240-4ebf-b199-11ce5f974892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "client = MongoClient(\"mongodb+srv://sp8108:EjGpKKzivWxMhCJw@test2-cluster.jbe9c.mongodb.net/?retryWrites=true&w=majority&appName=test2-cluster\")\n",
    "#dbase = client['Robotics_RAG_System']\n",
    "dbase = client['testragfortokens']\n",
    "\n",
    "#assume qdrant client exists\n",
    "qdrant_client = QdrantClient(\n",
    "    url=\"https://b4f8040f-4d46-4bdd-af44-9e12d8f374df.europe-west3-0.gcp.cloud.qdrant.io:6333\",\n",
    "    api_key=\"K4rwnn7SPIghHVfRAM403BQYPulPm0Rl_9W-WUlX6UJlJuB6bhZgYA\",\n",
    ")\n",
    "\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "#token: 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\n",
    "#notebook_login()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xK31wz5FcTY_",
    "outputId": "c7da8a34-d8b7-468a-e3da-c338b403f01c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['_id', 'data_name', 'source', 'domain', 'url', 'content', 'embedding', 'preprocessed_text'])\n",
      "dict_keys(['_id', 'data_name', 'source', 'domain', 'url', 'content', 'embedding', 'preprocessed_text'])\n"
     ]
    }
   ],
   "source": [
    "for doc in dbase[\"data\"].find():\n",
    "    if doc['source'] == \"GitHub\":\n",
    "        print(doc.keys())\n",
    "        break\n",
    "\n",
    "for doc in dbase[\"data\"].find():\n",
    "    if doc['source'] == \"YouTube\":\n",
    "        print(doc.keys())\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ndd7YA7UcTY_",
    "outputId": "e25680a1-bb53-4420-f399-2ffdcf96a1ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "#llm = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "llm2 = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(llm2)\n",
    "model = GPT2LMHeadModel.from_pretrained(llm2)\n",
    "\n",
    "\n",
    "print(model.config.max_position_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Re8USpGtcTY_"
   },
   "outputs": [],
   "source": [
    "def retrieve_relevant_documents(query, top_k=5):\n",
    "    query_embedding = embedding_model.encode(query)\n",
    "    search_result = qdrant_client.search(\n",
    "        collection_name=\"testragfortokens\",\n",
    "        query_vector=query_embedding,\n",
    "        limit=top_k\n",
    "    )\n",
    "    return [hit.payload for hit in search_result]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Dj-EnvccTY_"
   },
   "outputs": [],
   "source": [
    "def generate_response(query, context):\n",
    "    #print(context, len(context))\n",
    "    prompt = f\"Context: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=input_ids.device)\n",
    "    pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    max_length = model.config.max_position_embeddings\n",
    "    #print(max_length)\n",
    "\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=1024,\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        temperature=0.7,\n",
    "        pad_token_id=pad_token_id,\n",
    "        attention_mask=attention_mask,\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wdGcSzbDcTY_"
   },
   "outputs": [],
   "source": [
    "def rag_pipeline(query):\n",
    "    all_relevant_docs = retrieve_relevant_documents(query)\n",
    "\n",
    "    #print(all_relevant_docs[0])\n",
    "\n",
    "    context = \"\\n\".join([doc['preprocessed_text'] for doc in all_relevant_docs])\n",
    "    #print(type(context))\n",
    "    context_size = len(context)\n",
    "    if context_size>=1024:\n",
    "      context = context[:1023]\n",
    "      '''words = context.split()\n",
    "        scale_factor = (context_size//1024 + 1)\n",
    "        words = words[::scale_factor]\n",
    "        context_new = \" \".join(words)\n",
    "        print(len(context_new))\n",
    "        context = context_new'''\n",
    "    response = generate_response(query, context)\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NREn2RjmcTY_",
    "outputId": "4aa2cb09-6d87-41b7-e444-cee8d6209916"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: navigatethroughposes invokes navigatethroughposes ros action server implemented bt navigator module input port goal type default vector n description goal pose take blackboard variable e g goal server name type default string n description action server name server timeout type default double description action server timeout m behavior tree type default string n description behavior tree absolute path none specified navigatethroughposes action server us default behavior tree output port error code id type default uint n description lowest error code list error code name parameter example behavior tree navigate pose w replanning recovery xml\n",
      "foxy galactic moving ros foxy galactic number stability improvement added specifically address navigatetopose action feedback update navigatetopose action feedback two improvement distance remaining integrates path pose report accurate distance remaining go previously field reported euclidean distance current pose goal pose addition estimated time remaining field field r\n",
      "\n",
      "Question: Tell me how can I navigate to a specific pose - include replanning aspects in your answer.\n",
      "\n",
      "Answer: You can use the following command to navigate through all your poses. It is recommended to use an image viewer to browse through the image and select a pose from the list, as it is faster to do so. (It's also a good idea to set the camera to zoom in, otherwise your viewer will not work.)\n",
      " (The following is a short explanation of how to walk through a whole set of poses: how you use a camera, how the pose is taken, and how it's used.) (This tutorial assumes that you are already familiar with the basic commands in the commands section.)\n",
      "\n",
      "\n",
      "(There are two ways to get a walkthrough of all of the poses you would like to see.) The first way is to run the command as a command line:\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_query = \"Tell me how can I navigate to a specific pose - include replanning aspects in your answer.\"\n",
    "answer = rag_pipeline(user_query)\n",
    "print(answer)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
