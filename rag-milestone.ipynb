{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0kpdhD6cTY8",
        "outputId": "3a96ec0f-2bd7-421e-b055-64f6f831d08d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.10.1)\n",
            "Requirement already satisfied: qdrant-client in /usr/local/lib/python3.10/dist-packages (1.12.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.7.0)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.68.1)\n",
            "Requirement already satisfied: grpcio-tools>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.68.1)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.26.4)\n",
            "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.10.1)\n",
            "Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.10.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.2.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (5.29.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (75.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.14.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant-client) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymongo qdrant-client nltk sentence-transformers transformers huggingface_hub torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1xxMQWJMcTY-"
      },
      "outputs": [],
      "source": [
        "import pymongo\n",
        "from pymongo import MongoClient\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import VectorParams, Distance\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, GPT2LMHeadModel, GPT2Tokenizer\n",
        "#from huggingface_hub import notebook_login\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYjzGNUtcTY-",
        "outputId": "f9c5236b-bcbb-408b-a263-4a560fe9a129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "client = MongoClient(\"mongodb+srv://sp8108:EjGpKKzivWxMhCJw@test2-cluster.jbe9c.mongodb.net/?retryWrites=true&w=majority&appName=test2-cluster\")\n",
        "#dbase = client['Robotics_RAG_System']\n",
        "dbase = client['newRAGsystem']\n",
        "\n",
        "#assume qdrant client exists\n",
        "qdrant_client = QdrantClient(\n",
        "    url=\"https://b4f8040f-4d46-4bdd-af44-9e12d8f374df.europe-west3-0.gcp.cloud.qdrant.io:6333\",\n",
        "    api_key=\"K4rwnn7SPIghHVfRAM403BQYPulPm0Rl_9W-WUlX6UJlJuB6bhZgYA\",\n",
        ")\n",
        "\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "#token: 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\n",
        "#notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK31wz5FcTY_",
        "outputId": "f0da4978-74e2-494a-9cf7-87c5b6915ef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['_id', 'data_name', 'source', 'domain', 'url', 'content', 'embedding', 'preprocessed_text'])\n",
            "dict_keys(['_id', 'data_name', 'source', 'domain', 'url', 'content', 'embedding', 'preprocessed_text'])\n"
          ]
        }
      ],
      "source": [
        "for doc in dbase[\"data\"].find():\n",
        "    if doc['source'] == \"GitHub\":\n",
        "        print(doc.keys())\n",
        "        break\n",
        "\n",
        "for doc in dbase[\"data\"].find():\n",
        "    if doc['source'] == \"YouTube\":\n",
        "        print(doc.keys())\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Ndd7YA7UcTY_"
      },
      "outputs": [],
      "source": [
        "#llm = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "llm2 = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(llm2)\n",
        "model = GPT2LMHeadModel.from_pretrained(llm2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Re8USpGtcTY_"
      },
      "outputs": [],
      "source": [
        "def retrieve_relevant_documents(query, top_k=5):\n",
        "    query_embedding = embedding_model.encode(query)\n",
        "    search_result = qdrant_client.search(\n",
        "        collection_name=\"newRAGsystem\",\n",
        "        query_vector=query_embedding,\n",
        "        limit=top_k\n",
        "    )\n",
        "    return [hit.payload for hit in search_result]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "_Dj-EnvccTY_"
      },
      "outputs": [],
      "source": [
        "def generate_response(query, context):\n",
        "    print(context, len(context))\n",
        "    prompt = f\"Context: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=input_ids.device)\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "    print(f\"Min index: {input_ids.min()}, Max index: {input_ids.max()}\")\n",
        "    print(f\"Tokenizer vocab size: {len(tokenizer)}\")\n",
        "    print(f\"Model vocab size: {model.config.vocab_size}\")\n",
        "    max_length = model.config.max_position_embeddings\n",
        "    print(max_length)\n",
        "\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_length=1024,\n",
        "        num_return_sequences=1,\n",
        "        no_repeat_ngram_size=2,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.7,\n",
        "        pad_token_id=pad_token_id,\n",
        "        attention_mask=attention_mask,\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "wdGcSzbDcTY_"
      },
      "outputs": [],
      "source": [
        "def rag_pipeline(query):\n",
        "    '''collections = ['ros_middleware', 'nav2_navigation', 'moveit2_motion_planning', 'gazebo_simulation', 'YouTube_extractions']\n",
        "    all_relevant_docs = []\n",
        "\n",
        "\n",
        "    for collection in collections:\n",
        "        relevant_docs = retrieve_relevant_documents(query, collection)\n",
        "        all_relevant_docs.extend(relevant_docs)'''\n",
        "\n",
        "    all_relevant_docs = retrieve_relevant_documents(query)\n",
        "\n",
        "    print(all_relevant_docs[0])\n",
        "\n",
        "    context = \"\\n\".join([doc['preprocessed_text'] for doc in all_relevant_docs])\n",
        "    print(type(context))\n",
        "    context_size = len(context)\n",
        "    if context_size>=1024:\n",
        "      context = context[:1023]\n",
        "      '''words = context.split()\n",
        "        scale_factor = (context_size//1024 + 1)\n",
        "        words = words[::scale_factor]\n",
        "        context_new = \" \".join(words)\n",
        "        print(len(context_new))\n",
        "        context = context_new'''\n",
        "    response = generate_response(query, context)\n",
        "\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NREn2RjmcTY_",
        "outputId": "0ab3cb53-63d2-4281-fb38-41fccc573998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'preprocessed_text': 'ro moveit robotic arm motion planning pretty old project mine tutorial code found', 'category': 'moveit2_motion_planning'}\n",
            "<class 'str'>\n",
            "ro moveit robotic arm motion planning pretty old project mine tutorial code found\n",
            "trajectory generation overview sequence processing following diagram show step process execute list command given sequence diagram also show resulting data structure processing step overviewprocessing overview class planningcontext following diagram show different class responsible loading different planning context eg ptp lin circ relationship diagclassplanningcontext relationship movegroupcapabilities comandlistmanager following diagram show relationship movegroupcapabilities commandlistmanager diagclasscapabilities blending algorithm description description used blending algorithm found\n",
            "dynamic object following html overview tutorial show use nav different task going point point b case use nav follow moving object distance indefinitely task useful case following person another robot sample video application could created using capability carry luggage robocup home test team performs test successfully real future world applic 1023\n",
            "Min index: 25, Max index: 37153\n",
            "Tokenizer vocab size: 50257\n",
            "Model vocab size: 50257\n",
            "1024\n",
            "Context: ro moveit robotic arm motion planning pretty old project mine tutorial code found\n",
            "trajectory generation overview sequence processing following diagram show step process execute list command given sequence diagram also show resulting data structure processing step overviewprocessing overview class planningcontext following diagram show different class responsible loading different planning context eg ptp lin circ relationship diagclassplanningcontext relationship movegroupcapabilities comandlistmanager following diagram show relationship movegroupcapabilities commandlistmanager diagclasscapabilities blending algorithm description description used blending algorithm found\n",
            "dynamic object following html overview tutorial show use nav different task going point point b case use nav follow moving object distance indefinitely task useful case following person another robot sample video application could created using capability carry luggage robocup home test team performs test successfully real future world applic\n",
            "\n",
            "Question: Can you provide me with code for this task?\n",
            "\n",
            "Answer: Yes, as soon as I provide code I will provide the code.\n",
            " I have already written a lot of code, but only now can I create a task for it. It's a little more challenging than it looks. The problem is that when you create an object with an external name, it doesn't have to be something special. When you're creating a new task, you can do things like add/remove attributes, add a name attribute, change the value of the attribute and so on. But you don't need to create the task. You just need the information that you need. So I'm going to make a simple task that will do the following:\n",
            " (click on the image to go to the source of this video)\n",
            ".\n",
            "\n",
            "\n",
            "Let's say that a robot is travelling in the direction of a path. We want to do this when it's about to stop. What do we do when the robot stops and moves around the path? Well, we can create our own task and use it to add new attributes to our object. This task will act like a helper to my task:\n",
            "\n",
            " (add new method 'add_path' )\n",
            " and add the new attribute 'path'. If the object has a value, then the method is called on it and the methods are passed to it at the end of our task in a function call. In the example above, I've added the 'name' attribute on my object, and added a method called add_method(name, value) and that's it!\n",
            ", where the name and value are added to a variable. And the result of that method will be the next step. If we add another method that takes a parameter and returns a structure, that structure will change. For example, when adding a property to an array, the structure that is added will contain the property name. Add the final property 'property' to that array. Let's now add an attribute to one of my objects: (def index (and type) [1, 2, 3, 4])\n",
            "\n",
            "\n",
            ". (get-object (new-method 'index') (let [index (index 1) (for (name (value) type)) (object index) 'a' (put (var name) \"hello\") (obj index))))\n",
            "- (set-name 'foo' \"bar\")\n",
            "Now we'll use the same object as before to remove the last element from the list. Now, let's create another task to change this array from a different array: [3, 0, 1, 5]\n",
            "I'm not going anywhere. I'll create new tasks and create their properties. Then, if the array is empty, they can be changed to their values: '1', '2', etc. These new objects can then be added into my Task. Once the Task is finished, there's no need for an additional call to 'make_task_destroy'.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "user_query = \"Can you provide me with code for this task?\"\n",
        "answer = rag_pipeline(user_query)\n",
        "print(answer)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}